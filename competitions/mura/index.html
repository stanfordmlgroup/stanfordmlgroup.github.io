<!DOCTYPE html><!-- Author: Pranav Rajpurkar 2017--><html><head><meta charset="utf-8"><title>MURA Dataset: Towards Radiologist-Level Abnormality Detection in Musculoskeletal Radiographs</title><meta name="description" content="MURA is a large dataset of bone X-rays. Algorithms are tasked with determining whether an X-ray study is normal or abnormal."><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><link rel="image_src" type="image/jpeg" href="/logo.jpg"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link rel="icon" href="/favicon.ico" type="image/x-icon"><link href="/lib/bootstrap/css/bootstrap.min.css" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Lato:400,600" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Muli:400,600" rel="stylesheet"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/lib/simple-line-icons/css/simple-line-icons.css"><link href="/css/theme.css" rel="stylesheet"><link href="//cdn-images.mailchimp.com/embedcode/classic-10_7.css" rel="stylesheet" type="text/css"><link rel="stylesheet" type="text/css" href="/competitions/mura/css/index.css"><script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script><script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script><script src="/js/analytics.js"></script></head><body><nav class="navbar navbar-default navbar-fixed-top" id="mainNav"><div class="container"><!-- Brand and toggle get grouped for better mobile display--><div class="navbar-header"><a class="navbar-brand page-scroll" href="/">Stanford ML Group</a></div><!-- Collect the nav links, forms, and other content for toggling--></div></nav><section id="header"><div class="container"><div class="row"><div class="col-lg-12"><img id="title-image" src="/competitions/mura/img/logo.svg"><h2 id="page-subtitle">Bone X-Ray Deep Learning Competition</h2></div></div></div></section><section><div class="container"><div class="row"><div class="col-md-6"><h1>What is MURA?</h1><p>MURA (<b>mu</b>sculoskeletal <b>ra</b>diographs) is a large dataset of bone X-rays. Algorithms are tasked with determining whether an X-ray study is normal or abnormal.</p><p>Musculoskeletal conditions affect more than 1.7 billion people worldwide, and are the most common cause of severe, long-term pain and disability, with 30 million emergency department visits annually and increasing. We hope that our dataset can lead to significant advances in medical imaging technologies which can diagnose at the level of experts, towards improving healthcare access in parts of the world where access to skilled radiologists is limited.</p><p>MURA is one of the largest public radiographic image datasets. We're making this dataset available to the community and hosting a competition to see if your models can perform as well as radiologists on the task.</p><h2>How can I participate?</h2><p>Update: This competition is now closed.</p><p>MURA uses a hidden test set for official evaluation of models. Teams submit their executable code on Codalab, which is then run on a test set that is not publicly readable. Such a setup preserves the integrity of the test results.</p><p>Here's a tutorial walking you through official evaluation of your model. Once your model has been evaluated officially, your scores will be added to the leaderboard.</p><ul class="list-inline"><li><a class="btn btn-lg btn-default" href="https://worksheets.codalab.org/worksheets/0x42dda565716a4ee08d61f0a23656d8c0/">Submission Tutorial</a></li><li><a class="btn btn-lg btn-default" href="https://arxiv.org/abs/1712.06957">Read the Paper</a></li></ul></div><div class="col-md-6"><h1>Leaderboard</h1><p> Will your model perform as well as radiologists in detecting abnormalities in musculoskeletal X-rays?</p><table class="table performanceTable"><tr><th>Rank</th><th>Date</th><th>Model</th><th>Kappa</th></tr><tr class="human-row"><td></td><td></td><td>Best Radiologist Performance <em>Stanford University </em><a href="https://arxiv.org/abs/1712.06957">Rajpurkar & Irvin et al., 17</a></td><td>0.778</td></tr><tr><td class="rank">1 <br></td><td><span class="date label label-default">Nov 30, 2018</span></td><td style="word-break:break-word;">base-comb2-xuan-v3(ensemble)<em> jzhang Availink </em></td><td><b>0.843</b></td></tr><tr><td class="rank">2 <br></td><td><span class="date label label-default">Nov 06, 2018</span></td><td style="word-break:break-word;">base-comb2-xuan(ensemble)<em> jtzhang Availink </em></td><td>0.834</td></tr><tr><td class="rank">3 <br></td><td><span class="date label label-default">Oct 06, 2018</span></td><td style="word-break:break-word;">muti_type (ensemble model)<em> SCU_MILAB </em></td><td>0.833</td></tr><tr><td class="rank">4 <br></td><td><span class="date label label-default">Oct 02, 2018</span></td><td style="word-break:break-word;">base-comb4(ensemble)<em> jtzhang Availink </em></td><td>0.824</td></tr><tr><td class="rank">5 <br></td><td><span class="date label label-default">Nov 08, 2018</span></td><td style="word-break:break-word;">base-comb2-jun2(ensemble)</td><td>0.814</td></tr><tr><td class="rank">5 <br></td><td><span class="date label label-default">Nov 07, 2018</span></td><td style="word-break:break-word;">base-comb2-ping(ensemble)</td><td>0.814</td></tr><tr><td class="rank">6 <br></td><td><span class="date label label-default">Aug 22, 2018</span></td><td style="word-break:break-word;">base-comb3(ensemble)</td><td>0.805</td></tr><tr><td class="rank">7 <br></td><td><span class="date label label-default">Sep 14, 2018</span></td><td style="word-break:break-word;">double_res(ensemble model)<em> SCU_MILAB </em></td><td>0.804</td></tr><tr><td class="rank">8 <br></td><td><span class="date label label-default">Aug 24, 2018</span></td><td style="word-break:break-word;">double-dense-Axy-Axyf512<em> ensemble </em></td><td>0.795</td></tr><tr><td class="rank">9 <br></td><td><span class="date label label-default">Jul 24, 2018</span></td><td style="word-break:break-word;">densenet169_v2/single model</td><td>0.775</td></tr><tr><td class="rank">10 <br></td><td><span class="date label label-default">Aug 19, 2018</span></td><td style="word-break:break-word;">ianpan (ensemble)<em> RIH 3D Lab </em></td><td>0.774</td></tr><tr><td class="rank">11 <br></td><td><span class="date label label-default">Jul 24, 2018</span></td><td style="word-break:break-word;">inceptionv3/single model</td><td>0.774</td></tr><tr><td class="rank">12 <br></td><td><span class="date label label-default">Jun 17, 2018</span></td><td style="word-break:break-word;">gcm (ensemble)<em> Peking University </em></td><td>0.773</td></tr><tr><td class="rank">12 <br></td><td><span class="date label label-default">Sep 10, 2018</span></td><td style="word-break:break-word;">ty101<em> single model </em></td><td>0.773</td></tr><tr><td class="rank">13 <br></td><td><span class="date label label-default">Aug 31, 2018</span></td><td style="word-break:break-word;">he_j</td><td>0.764</td></tr><tr><td class="rank">13 <br></td><td><span class="date label label-default">Aug 31, 2018</span></td><td style="word-break:break-word;">AIAPlus (ensemble)<em> Taiwan AI Academy </em><a class="link" href="http://aiacademy.tw">http://aiacademy.tw</a></td><td>0.764</td></tr><tr><td class="rank">14 <br></td><td><span class="date label label-default">Sep 04, 2018</span></td><td style="word-break:break-word;">SER_Net_Baseline (single model)<em> SJTU </em></td><td>0.764</td></tr><tr><td class="rank">15 <br></td><td><span class="date label label-default">Jul 14, 2018</span></td><td style="word-break:break-word;">Trs (single model)<em> SCU_MILAB </em></td><td>0.763</td></tr><tr><td class="rank">16 <br></td><td><span class="date label label-default">Sep 12, 2018</span></td><td style="word-break:break-word;">null</td><td>0.763</td></tr><tr><td class="rank">16 <br></td><td><span class="date label label-default">Aug 21, 2018</span></td><td style="word-break:break-word;">densenet single model unknown</td><td>0.763</td></tr><tr><td class="rank">17 <br></td><td><span class="date label label-default">Jul 16, 2018</span></td><td style="word-break:break-word;">null</td><td>0.755</td></tr><tr><td class="rank">17 <br></td><td><span class="date label label-default">Aug 24, 2018</span></td><td style="word-break:break-word;">dense-sep-xyz<em> ensemble </em></td><td>0.755</td></tr><tr><td class="rank">18 <br></td><td><span class="date label label-default">Nov 16, 2018</span></td><td style="word-break:break-word;">VGG19<em> single model </em></td><td>0.754</td></tr><tr><td class="rank">19 <br></td><td><span class="date label label-default">Jul 25, 2018</span></td><td style="word-break:break-word;">DenseNet001 (single model)<em> zhou </em></td><td>0.747</td></tr><tr><td class="rank">20 <br></td><td><span class="date label label-default">Aug 21, 2018</span></td><td style="word-break:break-word;">dn169-Aftrva(single)<em> AliHealth </em></td><td>0.747</td></tr><tr><td class="rank">21 <br></td><td><span class="date label label-default">Jul 14, 2018</span></td><td style="word-break:break-word;">type_resnet (single model)<em> CCLab </em></td><td>0.746</td></tr><tr><td class="rank">22 <br></td><td><span class="date label label-default">Dec 06, 2018</span></td><td style="word-break:break-word;">res101_da_sqtv(single)</td><td>0.746</td></tr><tr><td class="rank">23 <br></td><td><span class="date label label-default">Jun 18, 2018</span></td><td style="word-break:break-word;">VGG19 (single model)<em> ZHAW </em></td><td>0.744</td></tr><tr><td class="rank">24 <br></td><td><span class="date label label-default">Jul 02, 2018</span></td><td style="word-break:break-word;">ImageXrModel-001 (single model)<em> Ruslan Baikulov </em></td><td>0.737</td></tr><tr><td class="rank">25 <br></td><td><span class="date label label-default">Oct 04, 2018</span></td><td style="word-break:break-word;">ExtremityModel<em> ensemble </em></td><td>0.734</td></tr><tr><td class="rank">26 <br></td><td><span class="date label label-default">Jan 20, 2019</span></td><td style="word-break:break-word;">DenseAttention (single model)<em> BIT </em></td><td>0.727</td></tr><tr><td class="rank">26 <br></td><td><span class="date label label-default">Aug 12, 2018</span></td><td style="word-break:break-word;">base169-AllParts-diffParts-tv(ensemble)<em> MSFT-research </em></td><td>0.727</td></tr><tr><td class="rank">27 <br></td><td><span class="date label label-default">Mar 14, 2019</span></td><td style="word-break:break-word;">Resology14 (ensemble)<em> Rology </em><a class="link" href="http://www.rology.net">http://www.rology.net</a></td><td>0.725</td></tr><tr><td class="rank">27 <br></td><td><span class="date label label-default">Sep 28, 2018</span></td><td style="word-break:break-word;">aiinside</td><td>0.725</td></tr><tr><td class="rank">28 <br></td><td><span class="date label label-default">Dec 06, 2018</span></td><td style="word-break:break-word;">inc3_sqtv(single)<em> MIT AI </em></td><td>0.724</td></tr><tr><td class="rank">29 <br></td><td><span class="date label label-default">Aug 21, 2018</span></td><td style="word-break:break-word;">base-model-Atv(single)<em> Avail-AI </em></td><td>0.717</td></tr><tr><td class="rank">30 <br></td><td><span class="date label label-default">Dec 11, 2018</span></td><td style="word-break:break-word;">incev3_xy(single)<em> UCB </em></td><td>0.716</td></tr><tr><td class="rank">31 <br></td><td><span class="date label label-default">Jul 19, 2018</span></td><td style="word-break:break-word;">nasnet_mobile/single model</td><td>0.712</td></tr><tr><td class="rank">32 <br></td><td><span class="date label label-default">Mar 14, 2019</span></td><td style="word-break:break-word;">kmle-second (ensemble)<em> kmle </em></td><td>0.707</td></tr><tr><td class="rank">33 <br></td><td><span class="date label label-default">Jul 30, 2018</span></td><td style="word-break:break-word;">dn169-baseline (single model)<em> PKU </em></td><td>0.707</td></tr><tr><td class="rank">34 <br></td><td><span class="date label label-default">May 23, 2018</span></td><td style="word-break:break-word;">Stanford Baseline (ensemble)<em> Stanford University </em><a class="link" href="https://arxiv.org/abs/1712.06957">https://arxiv.org/abs/1712.06957</a></td><td>0.705</td></tr><tr><td class="rank">35 <br></td><td><span class="date label label-default">Mar 10, 2019</span></td><td style="word-break:break-word;">asa_model_nasnetmo (single)<em> toyohashi </em></td><td>0.702</td></tr><tr><td class="rank">36 <br></td><td><span class="date label label-default">Jul 11, 2018</span></td><td style="word-break:break-word;">mobilenet/single model</td><td>0.701</td></tr><tr><td class="rank">36 <br></td><td><span class="date label label-default">Jul 16, 2018</span></td><td style="word-break:break-word;">type_inception2(single model)<em> CCLab </em></td><td>0.701</td></tr><tr><td class="rank">37 <br></td><td><span class="date label label-default">Dec 06, 2018</span></td><td style="word-break:break-word;">term2-model0sqtv(single)</td><td>0.700</td></tr><tr><td class="rank">38 <br></td><td><span class="date label label-default">Jun 24, 2018</span></td><td style="word-break:break-word;">single-densenet169<em> single model </em></td><td>0.699</td></tr><tr><td class="rank">39 <br></td><td><span class="date label label-default">Aug 09, 2018</span></td><td style="word-break:break-word;">base169-AllParts-diffParts(ensemble)<em> MSFT-reseach </em></td><td>0.698</td></tr><tr><td class="rank">39 <br></td><td><span class="date label label-default">Oct 26, 2018</span></td><td style="word-break:break-word;">Joint-tv<em> single </em></td><td>0.698</td></tr><tr><td class="rank">39 <br></td><td><span class="date label label-default">Jul 02, 2018</span></td><td style="word-break:break-word;">Baseline169 (single model)<em> Personal </em></td><td>0.698</td></tr><tr><td class="rank">39 <br></td><td><span class="date label label-default">Aug 17, 2018</span></td><td style="word-break:break-word;">base<em> ensemble </em></td><td>0.698</td></tr><tr><td class="rank">39 <br></td><td><span class="date label label-default">Aug 21, 2018</span></td><td style="word-break:break-word;">baseAllPartsDiffParts-sq<em> ensemble </em></td><td>0.698</td></tr><tr><td class="rank">40 <br></td><td><span class="date label label-default">Jan 18, 2019</span></td><td style="word-break:break-word;">first-attempt-kmle (ensemble)<em> kmle </em></td><td>0.696</td></tr><tr><td class="rank">41 <br></td><td><span class="date label label-default">Dec 31, 2018</span></td><td style="word-break:break-word;">DenseNet_144<em> single model </em><a class="link" href="http://www.rology.net/">http://www.rology.net/</a></td><td>0.694</td></tr><tr><td class="rank">42 <br></td><td><span class="date label label-default">Jul 22, 2018</span></td><td style="word-break:break-word;">Densenet DI-MT<em> Single </em></td><td>0.690</td></tr><tr><td class="rank">43 <br></td><td><span class="date label label-default">Jul 13, 2018</span></td><td style="word-break:break-word;">dense169(ensemble)<em> mitAI </em></td><td>0.686</td></tr><tr><td class="rank">44 <br></td><td><span class="date label label-default">Oct 27, 2018</span></td><td style="word-break:break-word;">xception(single model)<em> bimal </em></td><td>0.686</td></tr><tr><td class="rank">45 <br></td><td><span class="date label label-default">Dec 23, 2018</span></td><td style="word-break:break-word;">{EnglebertDGC} (single model)<em> UCLouvain </em></td><td>0.684</td></tr><tr><td class="rank">46 <br></td><td><span class="date label label-default">Dec 06, 2018</span></td><td style="word-break:break-word;">res_daxy(single)<em> CMU ml </em></td><td>0.680</td></tr><tr><td class="rank">47 <br></td><td><span class="date label label-default">Jan 16, 2019</span></td><td style="word-break:break-word;">GoGoing (ensemble)<em> Inner Mongolia University </em></td><td>0.678</td></tr><tr><td class="rank">48 <br></td><td><span class="date label label-default">Dec 11, 2018</span></td><td style="word-break:break-word;">inceptionresnetv2_tv(single)<em> baidu AI </em></td><td>0.676</td></tr><tr><td class="rank">49 <br></td><td><span class="date label label-default">Jun 10, 2018</span></td><td style="word-break:break-word;">ResNet (single model)<em> UCSC CE graduate student huimin yan </em></td><td>0.675</td></tr><tr><td class="rank">49 <br></td><td><span class="date label label-default">Aug 18, 2018</span></td><td style="word-break:break-word;">{monica_v1}(single model)<em> Zzmonica </em></td><td>0.675</td></tr><tr><td class="rank">50 <br></td><td><span class="date label label-default">Jul 09, 2018</span></td><td style="word-break:break-word;">null</td><td>0.664</td></tr><tr><td class="rank">51 <br></td><td><span class="date label label-default">Jan 12, 2019</span></td><td style="word-break:break-word;">PFResNet (single model)<em> USTC_Math_1222 </em></td><td>0.664</td></tr><tr><td class="rank">52 <br></td><td><span class="date label label-default">Nov 29, 2018</span></td><td style="word-break:break-word;">{DenseNet_169} (single model)<em> Rology </em><a class="link" href="http://www.rology.net">http://www.rology.net</a></td><td>0.662</td></tr><tr><td class="rank">53 <br></td><td><span class="date label label-default">Jan 31, 2019</span></td><td style="word-break:break-word;">DenseNet_v2<em> single model </em><a class="link" href="http://www.rology.net">http://www.rology.net</a></td><td>0.661</td></tr><tr><td class="rank">54 <br></td><td><span class="date label label-default">Sep 03, 2018</span></td><td style="word-break:break-word;">DenseNet002 (single model)<em> zhou </em></td><td>0.660</td></tr><tr><td class="rank">55 <br></td><td><span class="date label label-default">Nov 05, 2018</span></td><td style="word-break:break-word;">DenseNet (single model)<em> Rology </em><a class="link" href="http://www.rology.net/">http://www.rology.net/</a></td><td>0.659</td></tr><tr><td class="rank">56 <br></td><td><span class="date label label-default">Jul 01, 2018</span></td><td style="word-break:break-word;">Baseline169-v0.2 (single)<em> Personal </em></td><td>0.659</td></tr><tr><td class="rank">57 <br></td><td><span class="date label label-default">Jul 08, 2018</span></td><td style="word-break:break-word;">madcarrot</td><td>0.653</td></tr><tr><td class="rank">58 <br></td><td><span class="date label label-default">Dec 06, 2018</span></td><td style="word-break:break-word;">base_largexy(single)<em> Tsinghua Deep Learning </em></td><td>0.652</td></tr><tr><td class="rank">59 <br></td><td><span class="date label label-default">Jun 30, 2018</span></td><td style="word-break:break-word;">zhy</td><td>0.638</td></tr><tr><td class="rank">60 <br></td><td><span class="date label label-default">Jul 01, 2018</span></td><td style="word-break:break-word;">Densenet121 (single model)<em> Personal </em></td><td>0.629</td></tr><tr><td class="rank">61 <br></td><td><span class="date label label-default">Oct 26, 2018</span></td><td style="word-break:break-word;">baseJoint-tvsq(single)<em> ali </em></td><td>0.624</td></tr><tr><td class="rank">62 <br></td><td><span class="date label label-default">Dec 31, 2018</span></td><td style="word-break:break-word;">ConvNet<em> single model </em><a class="link" href="http://www.rology.net/">http://www.rology.net/</a></td><td>0.599</td></tr><tr><td class="rank">63 <br></td><td><span class="date label label-default">Jan 31, 2019</span></td><td style="word-break:break-word;">Ensemble_V0<em> ensemble model </em><a class="link" href="http://www.rology.net/">http://www.rology.net/</a></td><td>0.599</td></tr><tr><td class="rank">64 <br></td><td><span class="date label label-default">Aug 29, 2018</span></td><td style="word-break:break-word;">Inception-ResNet-v2 (single model)<em> Royal Holloway </em></td><td>0.597</td></tr><tr><td class="rank">64 <br></td><td><span class="date label label-default">Aug 28, 2018</span></td><td style="word-break:break-word;">Inception-ResNet-v2 (single model)<em> Royal Holloway </em></td><td>0.597</td></tr><tr><td class="rank">65 <br></td><td><span class="date label label-default">Jul 26, 2018</span></td><td style="word-break:break-word;">Bhaukali_v1.0 (single model)<em> IIT BHU, Varanasi </em></td><td>0.581</td></tr><tr><td class="rank">66 <br></td><td><span class="date label label-default">Jul 21, 2018</span></td><td style="word-break:break-word;">inceptionv3-pci (single model)<em> PCI </em></td><td>0.578</td></tr><tr><td class="rank">67 <br></td><td><span class="date label label-default">Jul 12, 2018</span></td><td style="word-break:break-word;">DN169<em> single </em></td><td>0.574</td></tr><tr><td class="rank">68 <br></td><td><span class="date label label-default">Jul 31, 2018</span></td><td style="word-break:break-word;">Densenet169-lite(single model)<em> Tang </em></td><td>0.560</td></tr><tr><td class="rank">69 <br></td><td><span class="date label label-default">Aug 29, 2018</span></td><td style="word-break:break-word;">ensemble1<em> ensemble </em></td><td>0.534</td></tr><tr><td class="rank">70 <br></td><td><span class="date label label-default">Jul 06, 2018</span></td><td style="word-break:break-word;">DenseNet (single model)<em> Zhou </em></td><td>0.518</td></tr></table></div></div></div></section><section class="gray"><div class="container"><div class="row"><div class="col-md-7"><h2>How did we collect MURA?</h2><p>MURA is a dataset of musculoskeletal radiographs consisting of 14,863 studies from 12,173 patients, with a total of 40,561 multi-view radiographic images. Each belongs to one of seven standard upper extremity radiographic study types: elbow, finger, forearm, hand, humerus, shoulder, and wrist. Each study was manually labeled as normal or abnormal by board-certified radiologists from the Stanford Hospital at the time of clinical radiographic interpretation in the diagnostic radiology environment between 2001 and 2012.</p><h3>Test Set Collection</h3><p>To evaluate models and get a robust estimate of radiologist performance, we collected additional labels from six board-certified Stanford radiologists on the test set, consisting of 207 musculoskeletal studies. The radiologists individually retrospectively reviewed and labeled each study in the test set as a DICOM file as normal or abnormal in the clinical reading room environment using the PACS system. The radiologists have 8.83 years of experience on average ranging from 2 to 25 years. We randomly chose 3 of these radiologists to create a gold standard, defined as the majority vote of labels of the radiologists.</p></div><div class="col-md-5"><img src="/competitions/mura/img/dataset.png"></div></div></div></section><section><div class="container"><div class="row"><div class="col-md-7"><h2>What is our baseline?</h2><p>Our baseline uses a 169-layer convolutional neural network to detect and localize abnormalities. The model takes as input one or more views for a study of an upper extremity. On each view, our 169-layer convolutional neural network predicts the probability of abnormality. We compute the overall probability of abnormality for the study by taking the arithmetic mean of the abnormality probabilities output by the network for each image. The model makes the binary prediction of abnormal if the probability of abnormality for the study is greater than 0.5.</p><p>The network uses a Dense Convolutional Network architecture, which connects each layer to every other layer in a feed-forward fashion to make the optimization of deep networks tractable. We replace the final fully connected layer with one that has a single output, after which we apply a sigmoid nonlinearity. We use Class Activation Maps to visualize the parts of the radiograph which contribute most to the model's prediction of abnormality.</p><img src="/competitions/mura/img/pipeline.svg"><h2>How does our baseline do?</h2><p>We evaluated our baseline on the Cohen’s kappa statistic, which expresses the agreement of the model with the gold standard. Baseline performance is comparable to radiologist performance in detecting abnormalities on finger studies and equivalent on wrist studies. However, baseline performance is lower than best radiologist performance in detecting abnormalities on elbow, forearm, hand, humerus, shoulder studies, and overall, indicating that the task is a good challenge for future research.</p><img src="/competitions/mura/img/kappa.png"></div><div class="col-md-5"><img src="/competitions/mura/img/mura-cam1.svg"><img src="/competitions/mura/img/mura-cam2.svg"><img src="/competitions/mura/img/mura-cam3.svg"><img src="/competitions/mura/img/mura-cam4.svg"></div></div></div></section><section class="gray"><div class="container"><div class="row"><div class="col-md-7"><h1>Downloading the Dataset (v1.0)</h1><p> Find the dataset on the <a href="https://stanfordaimi.azurewebsites.net/datasets/3e00d84b-d86e-4fed-b2a4-bfe3effd661b">Stanford AIMI website</a>.</p></div></div></div></section><section><div class="container"><div class="row"><div class="col-md-7"><h2>MURA: Large Dataset for Abnormality Detection in Musculoskeletal Radiographs.</h2><h3>Pranav Rajpurkar*, Jeremy Irvin*, Aarti Bagul, Daisy Ding, Tony Duan, Hershel Mehta, Brandon Yang, Kaylie Zhu, Dillon Laird, Robyn L. Ball, Curtis Langlotz, Katie Shpanskaya, Matthew P. Lungren, Andrew Y. Ng</h3><p>If you have questions about our work,
contact us at our <a href="https://groups.google.com/forum/#!forum/mura-dataset">google group</a>.</p><a class="btn btn-lg btn-default" href="https://arxiv.org/abs/1712.06957">Read the Paper</a></div></div></div></section><footer><div class="container"><div class="row"><div class="col-md-12 text-center"><a href="/"><img src="/img/stanfordmlgrouplogo.svg"></a></div></div></div></footer><script src="/lib/jquery/jquery.min.js"></script><script src="/lib/bootstrap/js/bootstrap.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script><script src="/js/theme.js"></script><script src="/competitions/mura/js/form.js"></script></body></html>