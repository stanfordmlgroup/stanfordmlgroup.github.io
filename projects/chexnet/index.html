<!DOCTYPE html><!-- Author: Pranav Rajpurkar 2017--><html><head><meta charset="utf-8"><title>CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning</title><meta name="description" content="Detecting Pneumonia from Chest X-Rays better than a radiologist."><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><link rel="image_src" type="image/jpeg" href="/logo.jpg"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link rel="icon" href="/favicon.ico" type="image/x-icon"><link href="/lib/bootstrap/css/bootstrap.min.css" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Lato:400,600" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Muli:400,600" rel="stylesheet"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/lib/simple-line-icons/css/simple-line-icons.css"><link href="/css/theme.css" rel="stylesheet"><link rel="stylesheet" type="text/css" href="/projects/chexnet/css/chexnet.css"><script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script><script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script><script src="/js/analytics.js"></script></head><body><nav class="navbar navbar-default navbar-fixed-top" id="mainNav"><div class="container"><!-- Brand and toggle get grouped for better mobile display--><div class="navbar-header"><a class="navbar-brand page-scroll" href="/">Stanford ML Group</a></div><!-- Collect the nav links, forms, and other content for toggling--></div></nav><section id="header"><div class="container"><div class="row"><div class="col-lg-8"><h1 id="page-title">CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning</h1><h2>Pranav Rajpurkar*, Jeremy Irvin*, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, Matthew P. Lungren, Andrew Y. Ng</h2></div></div></div></section><section><div class="container"><div class="row"><div class="col-md-7"><h2>We develop an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists.</h2><p>Chest X-rays are currently the best available method for diagnosing pneumonia, playing a crucial role in clinical care and epidemiological studies. Pneumonia is responsible for more than 1 million hospitalizations and 50,000 deaths per year in the US alone.</p><a class="btn btn-lg btn-default" href="https://arxiv.org/abs/1711.05225">Read our paper</a></div><div class="col-md-5"><div class="crossfade"><img class="bottom" src="/projects/chexnet/img/chest-cam.png"><img class="top" src="/projects/chexnet/img/chest-example.png"></div></div></div></div></section><section class="gray"><div class="container"><div class="row"><div class="col-md-7"><img src="/projects/chexnet/img/chex-main.svg" style="max-height:700px;"></div><div class="col-md-5"><h2>Our model, CheXNet, is a 121-layer convolutional neural network that inputs a chest X-ray image and outputs the probability of pneumonia along with a heatmap localizing the areas of the image most indicative of pneumonia. </h2><p>We train CheXNet on the recently released ChestX-ray14 dataset, which contains 112,120 frontal-view chest X-ray images individually labeled with up to 14 different thoracic diseases, including pneumonia. We use dense connections and batch normalization to make the optimization of such a deep network tractable.</p></div></div></div></section><section><div class="container"><div class="row"><div class="col-md-7"><h2>We train on ChestX-ray14, the largest publicly available chest X- ray dataset.</h2><p>The dataset, released by the NIH, contains 112,120 frontal-view X-ray images of 30,805 unique patients, annotated with up to 14 different thoracic pathology labels using NLP methods on radiology reports. We label images that have pneumonia as one of the annotated pathologies as positive examples and label all other images as negative examples for the pneumonia detection task.</p><p>We collected a test set of 420 frontal chest X-rays. Annotations were obtained independently from four practicing radiologists at Stanford University, who were asked to label all 14 pathologies. We then evaluate the performance of an individual radiologist by using the majority vote of the other 3 radiologists as ground truth. Similarly, we evaluate CheXNet using the majority vote of 3 of 4 radiologists, repeated four times to cover all groups of 3.</p></div><div class="col-md-5"><img src="/projects/chexnet/img/chest-example2.png"></div></div></div></section><section><div class="container"><div class="row"><div class="col-md-7"><img src="/projects/chexnet/img/results.png"></div><div class="col-md-5"><h2>We find that the model exceeds the average radiologist performance on the pneumonia detection task.</h2><p> We compute the F1 score for each individual radiologist
and for CheXNet against each of the other 4 labels
as ground truth. We report
the mean of the 4 resulting F1 scores for each radiologist
and for CheXNet, along with the average F1
across the radiologists.
We compare radiologists and our model on the F1
metric, which is the harmonic average of the precision and
recall. CheXNet achieves an F1 score of 0.435
(95% CI 0.387, 0.481), higher than the radiologist average
of 0.387 (95% CI 0.330, 0.442). We use the bootstrap to
find that the difference in performance is statistically significant.</p></div></div></div></section><section class="gray"><div class="container"><div class="row"><div class="col-md-7"><h3> With approximately 2 billion procedures per year, chest X-rays are the most common imaging examination tool used in practice, critical for screening, diagnosis, and management of diseases including pneumonia. However, an estimated two thirds of the global population lacks access to radiology diagnostics. With automation at the level of experts, we hope that this technology can improve healthcare delivery and increase access to medical imaging expertise in parts of the world where access to skilled radiologists is limited.</h3><a class="btn btn-lg btn-default" href="https://arxiv.org/abs/1711.05225">Read our paper</a></div></div></div></section><footer><div class="container"><div class="row"><div class="col-md-12 text-center"><a href="/"><img src="/img/stanfordmlgrouplogo.svg"></a></div></div></div></footer><script src="/lib/jquery/jquery.min.js"></script><script src="/lib/bootstrap/js/bootstrap.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script><script src="/js/theme.js"></script></body></html>