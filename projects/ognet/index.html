<!DOCTYPE html><!-- Author: Pranav Rajpurkar 2017--><html><head><meta charset="utf-8"><title>OGNet: Towards a Global Oil and Gas Infrastructure Database using Deep Learning on Remotely Sensed Imagery</title><meta name="description" content="Constructing and Oil and Gas Infrastructure Database using Deep Learning."><meta property="og:image" content="https://stanfordmlgroup.github.io/projects/ognet/img/fig1.png"><meta name="twitter:image" content="https://stanfordmlgroup.github.io/projects/ognet/img/fig1.png"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><link rel="image_src" type="image/jpeg" href="/logo.jpg"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link rel="icon" href="/favicon.ico" type="image/x-icon"><link href="/lib/bootstrap/css/bootstrap.min.css" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Lato:400,600" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Muli:400,600" rel="stylesheet"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/lib/simple-line-icons/css/simple-line-icons.css"><link href="/css/theme.css" rel="stylesheet"><link rel="stylesheet" type="text/css" href="/projects/chexnext/css/chexnext.css"><script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script><script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script><script src="/js/analytics.js"></script></head><body><nav class="navbar navbar-default navbar-fixed-top" id="mainNav"><div class="container"><!-- Brand and toggle get grouped for better mobile display--><div class="navbar-header"><a class="navbar-brand page-scroll" href="/">Stanford ML Group</a></div><!-- Collect the nav links, forms, and other content for toggling--></div></nav><div style="position: fixed; z-index: -98; width: 100%; top: -35px; left: -15px"><iframe src="/projects/ognet/res/detection.html" frameborder="0" width="100%" height="2000"></iframe></div><section id="header"><div class="container"><div class="row"><div class="col-lg-10"><h1>OGNet: Towards a Global Oil and Gas Infrastructure Database using Deep Learning on Remotely Sensed Imagery</h1><p>Hao Sheng *, Jeremy Irvin *, Sasankh Munukutla, Shawn Zhang, Christopher Cross, Kyle Story, Rose Rustowicz, Cooper Elsworth, Zuta Yang, Mark Omara, Ritesh Gautam, Robert B. Jackson, Andrew Y. Ng</p></div></div></div></section><section class="white"><div class="container"><div class="row"><div class="col-md-9"><h2>We developed and deployed a deep learning model called OGNet to detect oil and gas infrastructure in aerial imagery.</h2><p>At least a quarter of the warming that the Earth is experiencing today is due to anthropogenic methane emissions, with emissions from the oil and gas sector significantly contributing to the total anthropogenic methane budget. There are multiple satellites in orbit and planned for launch in the next few years which can detect and quantify these emissions; however, to attribute methane emissions to their sources on the ground, a comprehensive database of the locations and characteristics of emission sources worldwide is essential. Deep learning on remotely-sensed imagery has the potential to automatically detect and create a global database of oil and gas infrastructure.</p><a class="btn btn-lg btn-default" href="https://arxiv.org/abs/2011.07227">Read The Paper (Sheng & Irvin et al.)</a></div></div></div></section><section class="gray"><div class="container"><div class="row"><div class="col-md-6"><img src="/projects/ognet/img/fig1.png"></div><div class="col-md-6"><h2>We curated a dataset of aerial imagery capturing oil refineries.</h2><p>The dataset consists of 7,066 aerial images in total, with 149 images of oil refineries and 6,917 negative images containing visually similar objects and landscapes around oil refineries. We used aerial imagery between 2015 and 2019 from the <a href="https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/" target="_blank">National Agriculture Imagery Program (NAIP)</a>, which captures the continental U.S. at a minimum of 1m resolution. The images are mosaics of the most recent captures of the location and do not suffer from cloud cover or haze because images were acquired aerially on days with low cloud cover. Imagery was processed and downloaded using the <a href="https://www.descarteslabs.com/" target="_blank">Descartes Labs platform</a>. The dataset can be downloaded below (<a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 License</a>).</p><a class="btn btn-lg btn-default" href="http://download.cs.stanford.edu/deep/ognet/OGNetDevelopmentData.zip">Download the Dataset</a></div></div></div></section><section class="white"><div class="container"><div class="row"><div class="col-md-12"><img src="/projects/ognet/img/fig2.png" style="max-height:700px;"></div><div class="col-md-12"><h2>We developed and deployed a deep learning model called OGNet to classify imagery for the presence of oil refineries.</h2><p>For a single image, OGNet produces a probability that the image contains an oil and gas facility.  In order to convert the probability to a binary prediction, we used the threshold that lead to the highest precision (0.81) subject to a recall of 1.0 on the validation set.</p><p>To identify infrastructure in the continental U.S. using OGNet, we partition the region into equal 500 x 500 pixel tiles at 2.5m resolution leading to 5,082,722 tiles in total and run each of the tiles through OGNet. Any tile which was assigned a positive prediction is greedily merged with any positively classified adjacent tiles, and the mean of the centroids of each of the tiles within the merged group is used as the detected location.</p><p>OGNet detections were manually reviewed and all false positive detections were removed. We discovered that OGNet was able to detect oil and gas facilities other than oil refineries, so the remaining facilities were classified as oil refineries or petroleum terminals.  During this process, we also identified the number of storage tanks at each facility. An expert interpreter designed the annotation procedure and verified the detected facilities and their attributed characteristics.</p></div></div></div></section><section class="gray"><div class="container"><div class="row"><div class="col-md-7"><h2>OGNet detected several oil and gas facilities not present in four publicly available datasets.</h2><p>We compared the manually verified facilities detected by OGNet by combining four publicly available datasets, namely <a href="https://edx.netl.doe.gov/dataset/global-oil-gas-features-database" target="_blank">GOGI</a>, <a href="https://ghgdata.epa.gov/ghgp/main.do" target="_blank">GHGRP</a>, <a href="https://hifld-geoplatform.opendata.arcgis.com/" target="_blank">HIFLD</a>, and <a href="https://www.eia.gov/maps/layer_info-m.php" target="_blank">EIA. </a>We removed duplicate records by combining coordinates within 2 km of each other.</p><p>We counted the number of reported facilities which were detected by OGNet, and found it detected 73.5% of the oil refineries and 23.9% of the petroleum terminals in the combined dataset. Close to half of the "missed" oil refineries were due to inaccurate locations reported in the public datasets.</p><p>We counted the number of detected facilities which neither occur in the combined public dataset nor the training set, and found that OGNet detected 6 new oil refineries (including one abandoned facility) and 142 new petroleum terminals.</p><a class="btn btn-lg btn-default" href="http://download.cs.stanford.edu/deep/ognet/OGNetDeploymentData.csv">Download OGNet Detections (v1.0)</a><div class="pad"></div><p>Each detection is associated with a latitude and longitude, facility type, storage tank count, and whether the detection corresponds to multiple adjacent facilities.</p><p><b>Disclaimer: </b>This is the first version of the database produced by OGNet and has limitations which should be considered carefully.</p><ul><li> NAIP imagery does not always provide a very recent capture of a location (see <a href="https://www.fsa.usda.gov/programs-and-services/aerial-photography/status-maps/index" target="_blank">NAIP Status Maps</a>). Results could differ with other imagery sources.</li><li>The locations of detections are restricted to the coverage of NAIP, which only captures the continental U.S.</li><li>The locations are not always centered on the facility.</li><li>The storage tank counts are not always exact.</li></ul></div><div class="col-md-5"><h2> </h2><table class="table performanceTable"><thead> </thead><tr><th></th><th style="text-align:center;">Oil Refinery </th><th style="text-align:center;">Petroleum Terminal</th></tr><tbody></tbody><tr><td>Total Detections</td><td style="text-align:center;">114</td><td style="text-align:center;">336</td></tr><tr><td>Coverage of Benchmark Datasets </td><td style="text-align:center;">73.5% (108 / 147)</td><td style="text-align:center;">23.9% (292 / 1222)</td></tr><tr><td>New Detections </td><td style="text-align:center;">6</td><td style="text-align:center;">142</td></tr><tr><td>Example Image</td><td><img src="/projects/ognet/img/refinery.png" style="width:350px;"></td><td><img src="/projects/ognet/img/lng.png" style="width:350px;"></td></tr><p style="text-align:center;">Table 1. Statistics of the OGNet detections and comparison to benchmark datasets.</p></table></div></div><div class="row"><div class="col-md-12"><h2>Check out the interactive map below, containing oil refineres detected by OGNet!</h2><p>The radius of the circles is proportional to the number of storage tanks at each facility.</p></div></div></div></section><div style="position: relative; margin: 25%; z-index: -99; height: 50%"></div><section class="white"><div class="container"><div class="row"><div class="col-md-7"><h3>To learn more, read <a href="https://arxiv.org/abs/2011.07227">our publication </a>presented at the NeurIPS 2020 workshop on Tackling Climate Change with Machine Learning.</h3><div class="pad"></div><p>If you have questions about our work, contact us at:</p><h4><code>haosheng@cs.stanford.edu</code> and <code>jirvin16@cs.stanford.edu</code></h4></div></div></div></section><footer><div class="container"><div class="row"><div class="col-md-12 text-center"><a href="/"><img src="/img/stanfordmlgrouplogo.svg"></a></div></div></div></footer><script src="/lib/jquery/jquery.min.js"></script><script src="/lib/bootstrap/js/bootstrap.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script><script src="/js/theme.js"></script></body></html>