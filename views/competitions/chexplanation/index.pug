extends ../../layout

block title
  title CheXplanation Competition 

block description
  meta(name='description' content='CheXplanation is a competition for x-ray pathology segmentation based on a new radiologist-annotated segmentation dataset.')
  meta(property='og:image' content='https://stanfordmlgroup.github.io/competitions/chexplanation/img/title.png')
  meta(property='og:title' content='CheXplanation: A Chest X-Ray Segmentation Dataset And Competition.')
  meta(name='twitter:card' content='summary_large_image')
  meta(name='twitter:image' content='https://stanfordmlgroup.github.io/competitions/chexplanation/img/title.png')

block extralinks
  link(href="//cdn-images.mailchimp.com/embedcode/classic-10_7.css" rel="stylesheet" type="text/css")
  link(rel='stylesheet', type='text/css', href='/competitions/chexpert/css/index.css')


include ../../includes/profile


block content
  section#header
  .container
    .row
      .col-lg-14
        img#title-image(src='/competitions/chexplanation/img/CheXplanation.svg')
        h3#page-subtitle
          | A Chest X-Ray Segmentation Dataset And Competition
section
  .container
    .row
      .col-md-7
        h1 What is CheXplanation?
        p
          | CheXplanation is a radiologist-annotated segmentation dataset on chest X-rays and
          | competition for automated pathology localization.
        a.btn.btn-default(href='https://www.medrxiv.org/content/10.1101/2021.02.28.21252634v1')
          | Read the Paper (Saporta, Gui &amp; Agrawal et
          | al.)
        h2 Why CheXplanation?
        p
          | While deep learning has enabled automated medical imaging interpretation at a level shown to
          | surpass that of practicing
          | experts, the &ldquo;black box&rdquo; nature of neural networks represents a barrier to physicians&rsquo; trust and
          | model adoption in the clinical setting. Therefore, to encourage the development and validation
          | of more &ldquo;interpretable&rdquo; models for chest X-ray interpretation, we present a new
          | radiologist-annotated segmentation dataset and a competition for pathology localization.
      .col-md-5
        h2 Leaderboard (coming soon)
        p
          | Will your model perform as well as radiologists in localizing different pathologies in chest
          | X-rays?
        h3 How can I participate?
        p
          | CheXplanation uses a hidden test set with official evaluation of models. Teams submit
          | binary segmentation masks per pathology which will be compared against the reference
          | segmentations using mIoU (mean intersection over union). We also give teams the option to submit
          | confidence scores relating to each pixel for pointing game evaluation.
        p Submission format and tutorial is in progress.
        ul.list-inline
          li
            a.btn.btn-lg.btn-default(href='https://worksheets.codalab.org/worksheets/0x693b0063ee504702b21f94ffb2d99c6d/')
              | Submission
              | Tutorial (In Progress)
          li
section.gray
  .container
    .row
      .col-md-7
        h2 How did we produce the CheXplanation dataset?
        p
          | The dataset&rsquo;s chest X-rays came from CheXpert, a large public dataset for chest X-ray
          | interpretation. We obtained pixel-level reference segmentations on the CheXpert validation and
          | test sets from two board-certified radiologists. For each chest X-ray, the radiologists were
          | asked to segment any of the following 10 conditions that were present in that chest X-ray, as
          | determined by CheXpert&rsquo;s ground-truth labels: Airspace Opacity, Atelectasis, Cardiomegaly,
          | Consolidation, Edema, Enlarged Cardiomediastinum, Lung Lesion, Pleural Effusion, Pneumothorax,
          | and Support Devices.
          | We also established a human benchmark by collecting segmentations from three additional
          | radiologists. These radiologists were also asked to segment the 10 conditions of interest
          | present on each chest X-ray, as determined by CheXpert&rsquo;s ground-truth labels.
        h2 What is our baseline model?
        p
          | Our baseline model leveraged saliency method, a weakly-supervised learning technique to generate
          | segmentations. For each chest X-ray, we used Grad-CAM to
          | generate heatmaps for each of the ten pathologies. We then applied a threshold to the heat maps
          | to produce binary segmentations in order to evaluate their overlap
          | with the radiologist reference segmentations. You may read the full details in the linked paper.
      .col-md-8
        img(src='/competitions/chexplanation/img/pipeline.png')
        p
          | * Note: Only positive pathologies are shown in our example figure.
section
  .container
    .row
      .col-md-8
        h2 Validation and Test Sets
        p
          | The&nbsp;CheXpert&nbsp;validation set consists of 234 chest&nbsp;X-rays from 200 patients randomly
          | sampled from the full&nbsp;dataset&nbsp;and was labeled according to the consensus of three
          | board-certified radiologists. The test set consists of 668 chest&nbsp;X-rays from 500 patients not
          | included in the training or validation sets and was labeled according to the consensus of five
          | board-certified radiologists.
        p
          | We provide the original X-ray images and reference segmentations of the validation set. The test
          | set will be used as a held-out set for leaderboard evaluation.
section.gray
  .container
    .row
      .col-md-7
        h1 Downloading the Dataset (v1.0)
        p
          | Please read the Stanford University School of Medicine CheXplanation Dataset Research Use
          | Agreement.
          | Once you register to download the CheXplanation dataset, you will receive a link to the download
          | over email. Note that you may not share the link to download the dataset with others.
        #agreement.well
          h3
            | Stanford University School of Medicine CheXplanation Dataset Research Use Agreement
          p
            | By registering for downloads from the CheXplanation Dataset, you are agreeing to this
            | Research
            | Use Agreement, as well as to the Terms of Use of the Stanford University School of Medicine
            | website as posted and updated periodically at http://www.stanford.edu/site/terms/.
          p
            | 1. Permission is granted to view and use the CheXplanation Dataset without charge for
            | personal,
            | non-commercial research purposes only. Any commercial use, sale, or other monetization is
            | prohibited.
          p
            | 2. Other than the rights granted herein, the Stanford University School of Medicine
            | (&ldquo;School of Medicine&rdquo;) retains all rights, title, and interest in the
            | CheXplanation
            | Dataset.
          p
            | 3. You may make a verbatim copy of the CheXplanation Dataset for personal, non-commercial
            | research use as permitted in this Research Use Agreement. If another user within your
            | organization wishes to use the CheXplanationDataset, they must register as an individual
            | user
            | and comply with all the terms of this Research Use Agreement.
          p
            | 4. YOU MAY NOT DISTRIBUTE, PUBLISH, OR REPRODUCE A COPY of any portion or all of the
            | CheXplanation Dataset to others without specific prior written permission from the School of
            | Medicine.
          p
            | 5. YOU MAY NOT SHARE THE DOWNLOAD LINK to the CheXplanation dataset to others. If another
            | user
            | within your organization wishes to use the CheXplanation Dataset, they must register as an
            | individual user and comply with all the terms of this Research Use Agreement.
          p
            | 6. You must not modify, reverse engineer, decompile, or create derivative works from the
            | CheXplanation Dataset. You must not remove or alter any copyright or other proprietary
            | notices
            | in the CheXplanation Dataset.
          p
            | 7. The CheXplanation Dataset has not been reviewed or approved by the Food and Drug
            | Administration, and is for non-clinical, Research Use Only. In no event shall data or images
            | generated through the use of the CheXplanation Dataset be used or relied upon in the
            | diagnosis
            | or provision of patient care.
          p
            | 8. THE CheXplanation DATASET IS PROVIDED &quot;AS IS,&quot; AND STANFORD UNIVERSITY AND ITS
            | COLLABORATORS
            | DO NOT MAKE ANY WARRANTY, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO WARRANTIES OF
            | MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, NOR DO THEY ASSUME ANY LIABILITY OR
            | RESPONSIBILITY FOR THE USE OF THIS CheXplanation DATASET.
          p
            | 9. You will not make any attempt to re-identify any of the individual data subjects.
            | Re-identification of individuals is strictly prohibited. Any re-identification of any
            | individual data subject shall be immediately reported to the School of Medicine.
          p
            | 10. Any violation of this Research Use Agreement or other impermissible use shall be grounds
            | for immediate termination of use of this CheXplanation Dataset. In the event that the School
            | of
            | Medicine determines that the recipient has violated this Research Use Agreement or other
            | impermissible use has been made, the School of Medicine may direct that the undersigned data
            | recipient immediately return all copies of the CheXplanation Dataset and retain no copies
            | thereof even if you did not cause the violation or impermissible use.
          p
            | In consideration for your agreement to the terms and conditions contained here, Stanford
            | grants you permission to view and use the CheXplanation Dataset for personal, non-commercial
            | research. You may not otherwise copy, reproduce, retransmit, distribute, publish,
            | commercially exploit or otherwise transfer any material.
          h4 Limitation of Use
          p You may use CheXplanation Dataset for legal purposes only.
          p
            | You agree to indemnify and hold Stanford harmless from any claims, losses or damages,
            | including legal fees, arising out of or resulting from your use of the CheXplanation Dataset
            | or
            | your violation or role in violation of these Terms. You agree to fully cooperate in
            | Stanford&rsquo;s defense against any such claims. These Terms shall be governed by and
            | interpreted in accordance with the laws of California.
        // Begin Mailchimp Signup Form
        // Begin Mailchimp Signup Form
        link(href='//cdn-images.mailchimp.com/embedcode/classic-10_7.css' rel='stylesheet' type='text/css')
        style(type='text/css').
          #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }
          /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.
          We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
        #mc_embed_signup
          form#mc-embedded-subscribe-form.validate(action='https://github.us1.list-manage.com/subscribe/post?u=3a5e298b67f430e9850d43c02&id=461e951eda' method='post' name='mc-embedded-subscribe-form' target='_blank' novalidate='')
            #mc_embed_signup_scroll
              h2 CheXplanation-v1.0
              .indicates-required
                span.asterisk *
                |  indicates required
              .mc-field-group
                label(for='mce-EMAIL')
                  | Email Address  
                  span.asterisk *
                input#mce-EMAIL.required.email(type='email' value='' name='EMAIL')
              .mc-field-group
                label(for='mce-FNAME')
                  | First Name  
                  span.asterisk *
                input#mce-FNAME.required(type='text' value='' name='FNAME')
              .mc-field-group
                label(for='mce-LNAME')
                  | Last Name  
                  span.asterisk *
                input#mce-LNAME.required(type='text' value='' name='LNAME')
              .mc-field-group
                label(for='mce-MMERGE3')
                  | School/Organization  
                  span.asterisk *
                input#mce-MMERGE3.required(type='text' value='' name='MMERGE3')
              .mc-field-group
                label(for='mce-MMERGE4')
                  | Role/Title  
                  span.asterisk *
                input#mce-MMERGE4.required(type='text' value='' name='MMERGE4')
              #mce-responses.clear
                #mce-error-response.response(style='display:none')
                #mce-success-response.response(style='display:none')
              // real people should not fill this in and expect good things - do not remove this or risk form bot signups
              div(style='position: absolute; left: -5000px;' aria-hidden='true')
                input(type='text' name='b_3a5e298b67f430e9850d43c02_461e951eda' tabindex='-1' value='')
              .clear
                input#mc-embedded-subscribe.button(type='submit' value='Subscribe' name='subscribe')
        script(type='text/javascript' src='//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js')
        script(type='text/javascript').
          (function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[3]='MMERGE3';ftypes[3]='text';fnames[4]='MMERGE4';ftypes[4]='text';}(jQuery));var $mcj = jQuery.noConflict(true);
        // End mc_embed_signup
section
  .container
    .row
      .col-md-7
        h2
          | Deep learning saliency maps do not accurately highlight diagnostically relevant regions for
          | medical image interpretation
        h3
          | Adriel Saporta *, Xiaotong Gui *, Ashwin Agrawal *, Anuj Pareek, Steven QH Truong, Chanh DT
          | Nguyen, Van-Doan Ngo, Jayne Seekins, Francis G Blankenberg, Andrew Ng, Matthew P Lungren, Pranav
          | Rajpurkar
        p
          | If you have questions about our work,
          | contact us at xgui@stanford.edu
        a.btn.btn-lg.btn-default(href='https://www.medrxiv.org/content/10.1101/2021.02.28.21252634v1')
          | Read the Paper

